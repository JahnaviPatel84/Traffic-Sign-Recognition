{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a51592e-3faf-45dd-a418-2f82d7a0dc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid training samples: 39209\n",
      "Train: 31367 | Val: 7842\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = \"data\"\n",
    "TRAIN_CSV = os.path.join(BASE_DIR, \"Train.csv\")\n",
    "TRAIN_IMG_DIR = os.path.join(BASE_DIR, \"train\")\n",
    "\n",
    "# Load train CSV\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "# Fix path: remove \"Train/\" if present in CSV\n",
    "train_df['Path'] = train_df['Path'].str.replace(\"Train/\", \"\", regex=False)\n",
    "\n",
    "# Create full image path\n",
    "train_df['FullPath'] = train_df['Path'].apply(lambda p: os.path.join(TRAIN_IMG_DIR, p))\n",
    "\n",
    "# Filter rows where image file exists\n",
    "train_df = train_df[train_df['FullPath'].apply(os.path.exists)].reset_index(drop=True)\n",
    "print(f\"Valid training samples: {len(train_df)}\")\n",
    "\n",
    "# Drop FullPath (optional)\n",
    "train_df = train_df.drop(columns=['FullPath'])\n",
    "\n",
    "# Train/val split\n",
    "train_df_split, val_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.2,\n",
    "    stratify=train_df['ClassId'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_df_split)} | Val: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a395d0e5-9578-473a-9389-238f81d65ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajhna\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class GTSRBDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root_dir, self.data.iloc[idx]['Path'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = int(self.data.iloc[idx]['ClassId'])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dce2257-cb68-4e1a-9090-c7bf4e2ceef4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Augmented transform for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# Clean transform for validation\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = GTSRBDataset(train_df_split, root_dir=os.path.join(BASE_DIR, \"train\"), transform=train_transform)\n",
    "val_dataset = GTSRBDataset(val_df, root_dir=os.path.join(BASE_DIR, \"train\"), transform=val_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e4f73dd-d59c-4624-9188-527d9510c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TrafficSignCNN(nn.Module):\n",
    "    def __init__(self, num_classes=43):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 32 → 16\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 16 → 8\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # 8 → 4\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a5003bc-5f06-451b-8313-927480e9dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TrafficSignCNN().to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d0a0b87-26ee-43b9-ae90-c6ddc4dba7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, train_correct = 0.0, 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_acc = 100 * train_correct / len(train_loader.dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * val_correct / len(val_loader.dataset)\n",
    "        print(f\"[Epoch {epoch+1}] Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94cd32dc-5d19-458f-a1cd-25b31f0282d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Acc: 43.80% | Val Acc: 80.96%\n",
      "[Epoch 2] Train Acc: 85.52% | Val Acc: 95.43%\n",
      "[Epoch 3] Train Acc: 93.61% | Val Acc: 98.11%\n",
      "[Epoch 4] Train Acc: 96.31% | Val Acc: 97.84%\n",
      "[Epoch 5] Train Acc: 97.05% | Val Acc: 98.84%\n",
      "[Epoch 6] Train Acc: 97.77% | Val Acc: 99.06%\n",
      "[Epoch 7] Train Acc: 98.24% | Val Acc: 99.41%\n",
      "[Epoch 8] Train Acc: 98.14% | Val Acc: 99.31%\n",
      "[Epoch 9] Train Acc: 98.51% | Val Acc: 99.30%\n",
      "[Epoch 10] Train Acc: 98.74% | Val Acc: 99.20%\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f415e67-5325-4027-b26b-0198fe92471f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to traffic_sign_cnn.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "MODEL_PATH = \"traffic_sign_cnn.pth\"\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "\n",
    "print(f\"Model saved to {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "856cc5e1-2ba2-40ea-b197-8c063dc042a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set labeled: True\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(\"data/Test.csv\")\n",
    "test_img_dir = os.path.join(\"data\", \"test\")\n",
    "\n",
    "# Clean test paths (remove \"Test/\" prefix if needed)\n",
    "test_df['Path'] = test_df['Path'].str.replace(\"Test/\", \"\", regex=False)\n",
    "\n",
    "# Check if ClassId column exists\n",
    "has_labels = 'ClassId' in test_df.columns\n",
    "print(\"Test set labeled:\", has_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7b56d53-6d59-4e4d-ac8f-0dc3f4d62fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "test_dataset = GTSRBDataset(test_df, root_dir=test_img_dir, transform=val_transform)\n",
    "\n",
    "# Loader\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a932f4d-6fa2-4d16-bc29-e29ebb9a96d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels\n",
    "y_true_test, y_pred_test = get_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7c1854d-8f44-4deb-a45f-38b3da02ab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 94.62%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.8667    0.9204        60\n",
      "           1     0.9788    0.9639    0.9713       720\n",
      "           2     0.9494    0.9760    0.9625       750\n",
      "           3     0.9718    0.9200    0.9452       450\n",
      "           4     0.9968    0.9530    0.9744       660\n",
      "           5     0.8154    0.9603    0.8819       630\n",
      "           6     0.9752    0.7867    0.8708       150\n",
      "           7     0.9973    0.8200    0.9000       450\n",
      "           8     0.9018    0.9800    0.9393       450\n",
      "           9     0.9958    0.9917    0.9937       480\n",
      "          10     0.9732    0.9909    0.9820       660\n",
      "          11     0.9597    0.9071    0.9327       420\n",
      "          12     0.9510    0.9841    0.9672       690\n",
      "          13     0.9986    0.9931    0.9958       720\n",
      "          14     1.0000    0.9741    0.9869       270\n",
      "          15     0.9952    0.9905    0.9928       210\n",
      "          16     1.0000    1.0000    1.0000       150\n",
      "          17     0.9972    0.9972    0.9972       360\n",
      "          18     0.9901    0.7667    0.8642       390\n",
      "          19     0.9677    1.0000    0.9836        60\n",
      "          20     0.6475    1.0000    0.7860        90\n",
      "          21     0.8727    0.5333    0.6621        90\n",
      "          22     0.9910    0.9167    0.9524       120\n",
      "          23     0.9359    0.9733    0.9542       150\n",
      "          24     1.0000    0.9667    0.9831        90\n",
      "          25     0.9533    0.9354    0.9443       480\n",
      "          26     0.7347    1.0000    0.8471       180\n",
      "          27     0.7027    0.4333    0.5361        60\n",
      "          28     0.7797    0.9200    0.8440       150\n",
      "          29     0.7377    1.0000    0.8491        90\n",
      "          30     0.7607    0.5933    0.6667       150\n",
      "          31     0.9041    0.9778    0.9395       270\n",
      "          32     0.8806    0.9833    0.9291        60\n",
      "          33     0.9767    1.0000    0.9882       210\n",
      "          34     0.9835    0.9917    0.9876       120\n",
      "          35     0.9921    0.9615    0.9766       390\n",
      "          36     1.0000    0.8833    0.9381       120\n",
      "          37     1.0000    1.0000    1.0000        60\n",
      "          38     0.9691    1.0000    0.9843       690\n",
      "          39     1.0000    0.9667    0.9831        90\n",
      "          40     0.9556    0.9556    0.9556        90\n",
      "          41     0.9667    0.9667    0.9667        60\n",
      "          42     0.9444    0.9444    0.9444        90\n",
      "\n",
      "    accuracy                         0.9462     12630\n",
      "   macro avg     0.9322    0.9238    0.9228     12630\n",
      "weighted avg     0.9506    0.9462    0.9456     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "if has_labels:\n",
    "    test_acc = accuracy_score(y_true_test, y_pred_test)\n",
    "    print(f\"Final Test Accuracy: {test_acc * 100:.2f}%\\n\")\n",
    "    print(classification_report(y_true_test, y_pred_test, digits=4))\n",
    "else:\n",
    "    print(\"Test accuracy cannot be computed — no labels in Test.csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da0cce-8132-40cf-a302-c0e6ec9fc725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
